{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation Patching by attention layers, mlps, and every token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnsight import LanguageModel\n",
    "import torch\n",
    "torch.set_grad_enabled(False)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = LanguageModel(\"meta-llama/Llama-3.2-1B\", device_map=\"auto\", torch_dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.model.layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_LAYERS = llm.model.config.num_hidden_layers\n",
    "N_HEADS = llm.model.config.num_attention_heads\n",
    "hidden_size = llm.model.layers[0].self_attn.q_proj.weight.shape[0]\n",
    "HEAD_SIZE = hidden_size // N_HEADS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate the current directory\n",
    "current_dir = os.getcwd()\n",
    "print(f\"current_dir={current_dir}\")\n",
    "\n",
    "# Read from the csv file the sentences s1, s2, and last_sentence\n",
    "df = pd.read_csv(os.path.join(current_dir, \"sentences.csv\"))\n",
    "\n",
    "# Iterate over the rows of the dataframe and plot the patching effects for each row\n",
    "for i in range(1):\n",
    "    s1 = df.iloc[i][\"sentence1\"]\n",
    "    s2 = df.iloc[i][\"sentence2\"]\n",
    "    last_sentence = df.iloc[i][\"last_sentence\"]\n",
    "\n",
    "    prompt = f\"{s1}\\n{s2}\\nNow I will give the correct answer.\\n{last_sentence}\"\n",
    "    corrupted_prompt = f\"{s1}\\n{s2}\\nNow I will give the incorrect answer.\\n{last_sentence}\"\n",
    "\n",
    "    prompt_reversed = f\"{s2}\\n{s1}\\nNow I will give the correct answer.\\n{last_sentence}\"   \n",
    "    corrupted_prompt_reversed = f\"{s2}\\n{s1}\\nNow I will give the incorrect answer.\\n{last_sentence}\"\n",
    "\n",
    "    prompts = [prompt, corrupted_prompt]\n",
    "    prompts_reversed = [prompt_reversed, corrupted_prompt_reversed]\n",
    "\n",
    "    # Define the answers to these prompts, formatted as (correct, incorrect)\n",
    "    answers = [\n",
    "        (df.iloc[i][\"answer_sentence1\"], df.iloc[i][\"answer_sentence2\"]),\n",
    "    ]\n",
    "\n",
    "    answer_token_indices = [\n",
    "        [llm.tokenizer(answers[i][j])[\"input_ids\"][1] for j in range(2)]\n",
    "        for i in range(len(answers))\n",
    "    ]\n",
    "\n",
    "    patching_results, clean_tokens = run_activation_patching(prompts, prompts_reversed, answer_token_indices)\n",
    "    # plot_patching_effects_single_heatmap_mlp_attn_combined(patching_results, clean_tokens, i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_patching_effects_single_heatmap_mlp_attn_combined(patching_results, clean_tokens, prompt_row=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patching_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_reversed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_token_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_activation_patching(prompts, prompts_reversed, answer_token_indices):  \n",
    "    patching_results = {layer: {\"attn\": {}, \"mlp\": {}} for layer in range(N_LAYERS)}  # Pre-allocate layer keys\n",
    "    z_l = {}\n",
    "\n",
    "    # Clean run, grab clean activations for layer\n",
    "    with llm.trace(prompts[0]):\n",
    "        clean_tokens = llm.inputs[1][\"input_ids\"][0].save()\n",
    "        for layer in range(N_LAYERS):\n",
    "            z_l[layer] = {\n",
    "                \"attn\": llm.model.layers[layer].self_attn.output.save() ,\n",
    "                \"mlp\": llm.model.layers[layer].mlp.output.save()\n",
    "            }\n",
    "        # Get logits from lm_head\n",
    "        clean_logits = llm.lm_head.output\n",
    "        clean_logit_difference = (clean_logits[0, -1, answer_token_indices[0][0]] - clean_logits[0, -1, answer_token_indices[0][1]]).save()\n",
    "\n",
    "    # Clean run for reversed prompts, grab clean activations for layer\n",
    "    with llm.trace(prompts_reversed[0]):\n",
    "        clean_tokens = llm.inputs[1][\"input_ids\"][0].save()\n",
    "        for layer in range(N_LAYERS):\n",
    "            z_l[layer] = {\n",
    "                \"attn\": ((z_l[layer][\"attn\"][0] + llm.model.layers[layer].self_attn.output[0]) / 2).unsqueeze(0).save(), # do the average of the clean and reversed activations\n",
    "                \"mlp\": ((z_l[layer][\"mlp\"] + llm.model.layers[layer].mlp.output) / 2).save() # do the average of the clean and reversed activations\n",
    "            }\n",
    "        # Get logits from lm_head\n",
    "        clean_logits = llm.lm_head.output\n",
    "        clean_logit_difference = (clean_logits[0, -1, answer_token_indices[0][0]] - clean_logits[0, -1, answer_token_indices[0][1]]).save()\n",
    "\n",
    "    # Corrupted run, grab the corrupted logits for later comparison    \n",
    "    with llm.trace(prompts[1]):\n",
    "        corrupted_logits = llm.lm_head.output\n",
    "        corrupted_logit_difference = (corrupted_logits[0, -1, answer_token_indices[0][0]] - corrupted_logits[0, -1, answer_token_indices[0][1]]).save()\n",
    "    \n",
    "    # Corrupted run for reversed prompts, grab the corrupted logits for later comparison    \n",
    "    with llm.trace(prompts_reversed[1]):\n",
    "        corrupted_logits_reversed = llm.lm_head.output\n",
    "        corrupted_logit_difference_reversed = (corrupted_logits_reversed[0, -1, answer_token_indices[0][0]] - corrupted_logits_reversed[0, -1, answer_token_indices[0][1]]).save()\n",
    "    \n",
    "    # Take the average of the corrupted logit differences\n",
    "    print(\"corrupted_logit_difference=\", corrupted_logit_difference)\n",
    "    print(\"corrupted_logit_difference_reversed=\", corrupted_logit_difference_reversed)\n",
    "    corrupted_logit_difference_avg = (corrupted_logit_difference + corrupted_logit_difference_reversed) / 2\n",
    "\n",
    "    # Patching\n",
    "    # Start with the activation patching. We take the average of the clean and reversed activations and use the first prompt set for patching: iterate through all the layers\n",
    "    for layer in range(N_LAYERS):\n",
    "        for token_idx in range(len(clean_tokens)):  \n",
    "            with llm.trace(prompts[1]):\n",
    "                # Activation patching MLP\n",
    "                # mlp_output = llm.model.layers[layer].mlp.output.save() # for testing\n",
    "                llm.model.layers[layer].mlp.output[:, token_idx, :] = z_l[layer][\"mlp\"][:, token_idx, :]\n",
    "                patched_logits = llm.lm_head.output\n",
    "                patched_logit_difference = (patched_logits[0, -1, answer_token_indices[0][0]] - patched_logits[0, -1, answer_token_indices[0][1]]).save()\n",
    "                patched_result = (patched_logit_difference - corrupted_logit_difference_avg) / (clean_logit_difference - corrupted_logit_difference_avg)\n",
    "                patching_results[layer][\"mlp\"][f\"token_{token_idx}\"] = patched_result.item().save() \n",
    "\n",
    "            with llm.trace(prompts[1]):\n",
    "                # Activation patching attention\n",
    "                # self_attn_output = llm.model.layers[layer].self_attn.output.save() # for testing\n",
    "                llm.model.layers[layer].self_attn.output[0][:, token_idx, :] = z_l[layer][\"attn\"][0][:, token_idx, :]\n",
    "                patched_logits = llm.lm_head.output\n",
    "                patched_logit_difference = (patched_logits[0, -1, answer_token_indices[0][0]] - patched_logits[0, -1, answer_token_indices[0][1]]).save()\n",
    "                patched_result = (patched_logit_difference - corrupted_logit_difference_avg) / (clean_logit_difference - corrupted_logit_difference_avg)\n",
    "                patching_results[layer][\"attn\"][f\"token_{token_idx}\"] = patched_result.item().save() \n",
    "    \n",
    "    patching_results = {\n",
    "        \"clean_run_logit_difference\": clean_logit_difference,\n",
    "        \"corrupted_run_logit_difference\": corrupted_logit_difference_avg,\n",
    "        \"patching_results\": patching_results    \n",
    "    }\n",
    "\n",
    "    return patching_results, clean_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_patching_effects_single_heatmap_mlp_attn_combined(patching_results, clean_tokens, prompt_row):\n",
    "    # Plotting: Single heatmap with Attention and MLP interleaved on Y-axis\n",
    "    N_LAYERS = len(patching_results[\"patching_results\"])\n",
    "    seq_len = len(clean_tokens)\n",
    "\n",
    "    # Extract data for attention and MLP, interleaving them on the Y-axis\n",
    "    combined_effects = np.zeros((N_LAYERS * 2, seq_len))  # Each layer has two rows: Attention and MLP\n",
    "\n",
    "    for layer in range(N_LAYERS):\n",
    "        for token_idx in range(seq_len):\n",
    "            attn_effect = float(patching_results[\"patching_results\"][layer][\"attn\"][f\"token_{token_idx}\"].value)\n",
    "            mlp_effect = float(patching_results[\"patching_results\"][layer][\"mlp\"][f\"token_{token_idx}\"].value)\n",
    "            combined_effects[layer * 2, token_idx] = attn_effect      # Attention row\n",
    "            combined_effects[layer * 2 + 1, token_idx] = mlp_effect  # MLP row\n",
    "\n",
    "    clean_diff = float(patching_results[\"clean_run_logit_difference\"].item())\n",
    "    corrupted_diff = float(patching_results[\"corrupted_run_logit_difference\"].item())\n",
    "\n",
    "    # Create the heatmap\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    im = plt.imshow(combined_effects, cmap='RdBu', aspect='auto', vmin=-0.5, vmax=0.5)\n",
    "    plt.colorbar(im, label='Normalized Patching Effect')\n",
    "\n",
    "    # Customize axes\n",
    "    token_labels = [llm.tokenizer.decode([tok]) for tok in clean_tokens]\n",
    "    plt.xlabel('Token', fontsize=12)\n",
    "    plt.ylabel('Layer (Attention | MLP)', fontsize=12)\n",
    "    plt.title('Patching Effects by Layer and Token\\n(Clean: \"Paris\" vs Corrupted: \"Berlin\")', fontsize=14)\n",
    "\n",
    "    # X-axis: Token labels\n",
    "    plt.xticks(np.arange(seq_len), labels=token_labels, fontsize=10, rotation=45, ha='right')\n",
    "\n",
    "    # Y-axis: Interleave Attention and MLP labels for each layer\n",
    "    y_labels = []\n",
    "    for layer in range(N_LAYERS):\n",
    "        y_labels.extend([f'Attn {layer}', f'MLP {layer}'])\n",
    "    plt.yticks(np.arange(N_LAYERS * 2), labels=y_labels, fontsize=10)\n",
    "\n",
    "    # Add clean/corrupted context\n",
    "    plt.figtext(0.5, 0.01, f'Clean Logit Diff: {clean_diff:.3f} | Corrupted Logit Diff: {corrupted_diff:.3f}', \n",
    "                fontsize=11, ha='center')\n",
    "\n",
    "    # Adjust layout and save\n",
    "    plt.tight_layout(rect=[0, 0.05, 1, 0.95])\n",
    "    plt.savefig(f'patching_effects_heatmap_single_{prompt_row}.pdf', format='pdf', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "helmholtz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
