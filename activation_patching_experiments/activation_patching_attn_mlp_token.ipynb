{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation Patching by attention layers, mlps, and every token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnsight import LanguageModel\n",
    "import torch\n",
    "torch.set_grad_enabled(False)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = LanguageModel(\"meta-llama/Llama-3.2-1B\", device_map=\"auto\", torch_dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaDecoderLayer(\n",
       "  (self_attn): LlamaSdpaAttention(\n",
       "    (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "    (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "    (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "    (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (mlp): LlamaMLP(\n",
       "    (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "    (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "    (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "    (act_fn): SiLU()\n",
       "  )\n",
       "  (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "  (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.model.layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_LAYERS = llm.model.config.num_hidden_layers\n",
    "N_HEADS = llm.model.config.num_attention_heads\n",
    "hidden_size = llm.model.layers[0].self_attn.q_proj.weight.shape[0]\n",
    "HEAD_SIZE = hidden_size // N_HEADS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_dir=/Users/ivannaranjo/Documents/Helmholtz/experiments/hlmz-prep/activation_patching_experiments\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' print(\"Prompts:\")\\nfor i, p in enumerate(prompts):\\n    print(f\"  {i+1}. {p}\")\\n    \\nprint(\"\\nPrompts (Reversed):\")\\nfor i, p in enumerate(prompts_reversed):\\n    print(f\"  {i+1}. {p}\")\\n    \\nprint(\"\\nAnswers:\")\\nfor i, ans in enumerate(answers):\\n    print(f\"  {i+1}. Correct: \\'{ans[0]}\\', Incorrect: \\'{ans[1]}\\'\")\\n    \\nprint(\"\\nAnswer Token Indices:\")\\nfor i, indices in enumerate(answer_token_indices):\\n    print(f\"  {i+1}. Correct: {indices[0]}, Incorrect: {indices[1]}\") '"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Locate the current directory\n",
    "current_dir = os.getcwd()\n",
    "print(f\"current_dir={current_dir}\")\n",
    "\n",
    "# Read from the csv file the sentences s1, s2, and last_sentence\n",
    "df = pd.read_csv(os.path.join(current_dir, \"sentences.csv\"))\n",
    "s1 = df.iloc[1][\"sentence1\"]\n",
    "s2 = df.iloc[1][\"sentence2\"]\n",
    "last_sentence = df.iloc[1][\"last_sentence\"]\n",
    "\n",
    "prompt = f\"{s1}\\n{s2}\\nNow I will give the correct answer.\\n{last_sentence}\"\n",
    "prompt_reversed = f\"{s2}\\n{s1}\\nNow I will give the correct answer.\\n{last_sentence}\"   \n",
    "\n",
    "corrupted_prompt = f\"{s1}\\n{s2}\\nNow I will give the incorrect answer.\\n{last_sentence}\"\n",
    "corrupted_prompt_reversed = f\"{s2}\\n{s1}\\nNow I will give the incorrect answer.\\n{last_sentence}\"\n",
    "\n",
    "prompts = [prompt, corrupted_prompt]\n",
    "prompts_reversed = [prompt_reversed, corrupted_prompt_reversed]\n",
    "\n",
    "# Define the answers to these prompts, formatted as (correct, incorrect)\n",
    "answers = [\n",
    "    (df.iloc[1][\"answer_sentence1\"], df.iloc[1][\"answer_sentence2\"]),\n",
    "    (df.iloc[1][\"answer_sentence2\"], df.iloc[1][\"answer_sentence1\"])\n",
    "]\n",
    "\n",
    "# Tokenize clean and corrupted prompts\n",
    "clean_tokens = llm.tokenizer(prompts[0], return_tensors=\"pt\")[\"input_ids\"]\n",
    "corrupted_tokens = llm.tokenizer(prompts[1], return_tensors=\"pt\")[\"input_ids\"]\n",
    "\n",
    "answer_token_indices = [\n",
    "    [llm.tokenizer(answers[i][j])[\"input_ids\"][1] for j in range(2)]\n",
    "    for i in range(len(answers))\n",
    "]\n",
    "\n",
    "# print(\"Prompts:\")\n",
    "# for i, p in enumerate(prompts):\n",
    "#     print(f\"  {i+1}. {p}\")\n",
    "    \n",
    "# print(\"\\nPrompts (Reversed):\")\n",
    "# for i, p in enumerate(prompts_reversed):\n",
    "#     print(f\"  {i+1}. {p}\")\n",
    "    \n",
    "# print(\"\\nAnswers:\")\n",
    "# for i, ans in enumerate(answers):\n",
    "#     print(f\"  {i+1}. Correct: '{ans[0]}', Incorrect: '{ans[1]}'\")\n",
    "    \n",
    "# print(\"\\nAnswer Token Indices:\")\n",
    "# for i, indices in enumerate(answer_token_indices):\n",
    "#     print(f\"  {i+1}. Correct: {indices[0]}, Incorrect: {indices[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_activation_patching(prompts, answer_token_indices):  \n",
    "    patching_results = {layer: {\"attn\": {}, \"mlp\": {}} for layer in range(N_LAYERS)}  # Pre-allocate layer keys\n",
    "    z_l = {}\n",
    "\n",
    "    with llm.trace() as tracer:\n",
    "        # Clean run, grab clean activations for layer\n",
    "        with tracer.invoke(prompts[0]) as invoker:\n",
    "            clean_tokens = invoker.inputs[0][0][\"input_ids\"][0]\n",
    "            for layer in range(N_LAYERS):\n",
    "                z_l[layer] = {\n",
    "                    \"attn\": llm.model.layers[layer].self_attn.output.save(),\n",
    "                    \"mlp\": llm.model.layers[layer].mlp.output.save()\n",
    "                }\n",
    "            # Get logits from lm_head\n",
    "            clean_logits = llm.lm_head.output\n",
    "            clean_logit_difference = (clean_logits[0, -1, answer_token_indices[0][0]] - clean_logits[0, -1, answer_token_indices[0][1]]).save()\n",
    "\n",
    "        # Corrupter run, grab the corrupted logits for later comparison    \n",
    "        with tracer.invoke(prompts[1]) as invoker:\n",
    "            corrupted_tokens = invoker.inputs[0][0][\"input_ids\"][0]\n",
    "            corrupted_logits = llm.lm_head.output\n",
    "            corrupted_logit_difference = (corrupted_logits[0, -1, answer_token_indices[0][0]] - corrupted_logits[0, -1, answer_token_indices[0][1]]).save()\n",
    "        \n",
    "    # Patching\n",
    "    # Start with the activation patching: iterate through all the layers\n",
    "    for layer in range(N_LAYERS):\n",
    "        for token_idx in range(len(clean_tokens)):  \n",
    "            with llm.trace(prompts[1]):\n",
    "                # Activation patching MLP\n",
    "                # mlp_output = llm.model.layers[layer].mlp.output.save() # for testing\n",
    "                llm.model.layers[layer].mlp.output[:, token_idx, :] = z_l[layer][\"mlp\"][:, token_idx, :]\n",
    "                patched_logits = llm.lm_head.output\n",
    "                patched_logit_difference = (patched_logits[0, -1, answer_token_indices[0][0]] - patched_logits[0, -1, answer_token_indices[0][1]]).save()\n",
    "                patched_result = (patched_logit_difference - corrupted_logit_difference) / (clean_logit_difference - corrupted_logit_difference)\n",
    "                patching_results[layer][\"mlp\"][f\"token_{token_idx}\"] = patched_result.item().save() \n",
    "\n",
    "            with llm.trace(prompts[1]):\n",
    "                # Activation patching attention\n",
    "                # self_attn_output = llm.model.layers[layer].self_attn.output.save() # for testing\n",
    "                llm.model.layers[layer].self_attn.output[0][:, token_idx, :] = z_l[layer][\"attn\"][0][:, token_idx, :]\n",
    "                patched_logits = llm.lm_head.output\n",
    "                patched_logit_difference = (patched_logits[0, -1, answer_token_indices[0][0]] - patched_logits[0, -1, answer_token_indices[0][1]]).save()\n",
    "                patched_result = (patched_logit_difference - corrupted_logit_difference) / (clean_logit_difference - corrupted_logit_difference)\n",
    "                patching_results[layer][\"attn\"][f\"token_{token_idx}\"] = patched_result.item().save() \n",
    "\n",
    "    return patching_results, corrupted_logit_difference, clean_logit_difference, corrupted_tokens, clean_tokens\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "patching_results, corrupted_logit_difference, clean_logit_difference, corrupted_tokens, clean_tokens = run_activation_patching(prompts, answer_token_indices)\n",
    "patching_results_total = {\n",
    "    \"clean_run_logit_difference\": clean_logit_difference,\n",
    "    \"corrupted_run_logit_difference\": corrupted_logit_difference,\n",
    "    \"patching_results\": patching_results\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_patching_effects_single_heatmap_mlp_attn_combined(patching_results, clean_tokens):\n",
    "    # Plotting: Single heatmap with Attention and MLP interleaved on Y-axis\n",
    "    N_LAYERS = len(patching_results)\n",
    "    seq_len = len(clean_tokens)\n",
    "\n",
    "    # Extract data for attention and MLP, interleaving them on the Y-axis\n",
    "    combined_effects = np.zeros((N_LAYERS * 2, seq_len))  # Each layer has two rows: Attention and MLP\n",
    "\n",
    "    for layer in range(N_LAYERS):\n",
    "        for token_idx in range(seq_len):\n",
    "            attn_effect = float(patching_results[layer][\"attn\"][f\"token_{token_idx}\"].value)\n",
    "            mlp_effect = float(patching_results[layer][\"mlp\"][f\"token_{token_idx}\"].value)\n",
    "            combined_effects[layer * 2, token_idx] = attn_effect      # Attention row\n",
    "            combined_effects[layer * 2 + 1, token_idx] = mlp_effect  # MLP row\n",
    "\n",
    "    clean_diff = float(patching_results_total[\"clean_run_logit_difference\"].item())\n",
    "    corrupted_diff = float(patching_results_total[\"corrupted_run_logit_difference\"].item())\n",
    "\n",
    "    # Create the heatmap\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    im = plt.imshow(combined_effects, cmap='RdBu', aspect='auto', vmin=-0.5, vmax=0.5)\n",
    "    plt.colorbar(im, label='Normalized Patching Effect')\n",
    "\n",
    "    # Customize axes\n",
    "    token_labels = [llm.tokenizer.decode([tok]) for tok in clean_tokens]\n",
    "    plt.xlabel('Token', fontsize=12)\n",
    "    plt.ylabel('Layer (Attention | MLP)', fontsize=12)\n",
    "    plt.title('Patching Effects by Layer and Token\\n(Clean: \"Paris\" vs Corrupted: \"Berlin\")', fontsize=14)\n",
    "\n",
    "    # X-axis: Token labels\n",
    "    plt.xticks(np.arange(seq_len), labels=token_labels, fontsize=10, rotation=45, ha='right')\n",
    "\n",
    "    # Y-axis: Interleave Attention and MLP labels for each layer\n",
    "    y_labels = []\n",
    "    for layer in range(N_LAYERS):\n",
    "        y_labels.extend([f'Attn {layer}', f'MLP {layer}'])\n",
    "    plt.yticks(np.arange(N_LAYERS * 2), labels=y_labels, fontsize=10)\n",
    "\n",
    "    # Add clean/corrupted context\n",
    "    plt.figtext(0.5, 0.01, f'Clean Logit Diff: {clean_diff:.3f} | Corrupted Logit Diff: {corrupted_diff:.3f}', \n",
    "                fontsize=11, ha='center')\n",
    "\n",
    "    # Adjust layout and save\n",
    "    plt.tight_layout(rect=[0, 0.05, 1, 0.95])\n",
    "    plt.savefig('patching_effects_heatmap_single.pdf', format='pdf', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "helmholtz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
