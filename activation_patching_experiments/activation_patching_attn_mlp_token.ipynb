{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation Patching by attention layers, mlps, and every token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnsight import LanguageModel\n",
    "import einops\n",
    "import torch\n",
    "torch.set_grad_enabled(False)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = LanguageModel(\"meta-llama/Llama-3.2-1B\", device_map=\"auto\", torch_dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.model.layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_LAYERS = llm.model.config.num_hidden_layers\n",
    "N_HEADS = llm.model.config.num_attention_heads\n",
    "hidden_size = llm.model.layers[0].self_attn.q_proj.weight.shape[0]\n",
    "HEAD_SIZE = hidden_size // N_HEADS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"The capital of France is Paris.\n",
    "The capital of France is Berlin.\n",
    "Now I will give the correct answer.\n",
    "The capital of France is\"\"\"\n",
    "\n",
    "corrupted_prompt = \"\"\"The capital of France is Paris.\n",
    "The capital of France is Berlin.\n",
    "Now I will give the incorrect answer.\n",
    "The capital of France is\"\"\"\n",
    "\n",
    "prompts = [prompt, corrupted_prompt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the answers to these prompts, formatted as (correct, incorrect)\n",
    "answers = [\n",
    "    (\" Paris\", \" Berlin\"),\n",
    "    (\" Berlin\", \" Paris\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize clean and corrupted prompts\n",
    "clean_tokens = llm.tokenizer(prompts[0], return_tensors=\"pt\")[\"input_ids\"]\n",
    "corrupted_tokens = llm.tokenizer(prompts[1], return_tensors=\"pt\")[\"input_ids\"]\n",
    "\n",
    "answer_token_indices = [\n",
    "    [llm.tokenizer(answers[i][j])[\"input_ids\"][1] for j in range(2)]\n",
    "    for i in range(len(answers))\n",
    "]\n",
    "print(\"answer_token_indices=\", answer_token_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patching_results = {layer: {\"attn\": {}, \"mlp\": {}} for layer in range(N_LAYERS)}  # Pre-allocate layer keys\n",
    "z_l = {}\n",
    "\n",
    "with llm.trace() as tracer:\n",
    "    # Clean run, grab clean activations for layer\n",
    "    with tracer.invoke(prompts[0]) as invoker:\n",
    "        clean_tokens = invoker.inputs[0][0][\"input_ids\"][0]\n",
    "        for layer in range(N_LAYERS):\n",
    "            z_l[layer] = {\n",
    "                \"attn\": llm.model.layers[layer].self_attn.output.save(),\n",
    "                \"mlp\": llm.model.layers[layer].mlp.output.save()\n",
    "            }\n",
    "        # Get logits from lm_head\n",
    "        clean_logits = llm.lm_head.output\n",
    "        clean_logit_difference = (clean_logits[0, -1, answer_token_indices[0][0]] - clean_logits[0, -1, answer_token_indices[0][1]]).save()\n",
    "\n",
    "    # Corrupter run, grab the corrupted logits for later comparison    \n",
    "    with tracer.invoke(prompts[1]) as invoker:\n",
    "        corrupted_tokens = invoker.inputs[0][0][\"input_ids\"][0]\n",
    "        corrupted_logits = llm.lm_head.output\n",
    "        corrupted_logit_difference = (corrupted_logits[0, -1, answer_token_indices[0][0]] - corrupted_logits[0, -1, answer_token_indices[0][1]]).save()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patching\n",
    "# Start with the activation patching: iterate through all the layers\n",
    "for layer in range(N_LAYERS):\n",
    "    for token_idx in range(len(clean_tokens)):  \n",
    "        with llm.trace(prompts[1]):\n",
    "            # Activation patching MLP\n",
    "            # mlp_output = llm.model.layers[layer].mlp.output.save() # for testing\n",
    "            llm.model.layers[layer].mlp.output[:, token_idx, :] = z_l[layer][\"mlp\"][:, token_idx, :]\n",
    "            patched_logits = llm.lm_head.output\n",
    "            patched_logit_difference = (patched_logits[0, -1, answer_token_indices[0][0]] - patched_logits[0, -1, answer_token_indices[0][1]]).save()\n",
    "            patched_result = (patched_logit_difference - corrupted_logit_difference) / (clean_logit_difference - corrupted_logit_difference)\n",
    "            patching_results[layer][\"mlp\"][f\"token_{token_idx}\"] = patched_result.item().save() \n",
    "\n",
    "        with llm.trace(prompts[1]):\n",
    "            # Activation patching attention\n",
    "            # self_attn_output = llm.model.layers[layer].self_attn.output.save() # for testing\n",
    "            llm.model.layers[layer].self_attn.output[0][:, token_idx, :] = z_l[layer][\"attn\"][0][:, token_idx, :]\n",
    "            patched_logits = llm.lm_head.output\n",
    "            patched_logit_difference = (patched_logits[0, -1, answer_token_indices[0][0]] - patched_logits[0, -1, answer_token_indices[0][1]]).save()\n",
    "            patched_result = (patched_logit_difference - corrupted_logit_difference) / (clean_logit_difference - corrupted_logit_difference)\n",
    "            patching_results[layer][\"attn\"][f\"token_{token_idx}\"] = patched_result.item().save() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patching_results_total = {\n",
    "    \"clean_run_logit_difference\": clean_logit_difference,\n",
    "    \"corrupted_run_logit_difference\": corrupted_logit_difference,\n",
    "    \"patching_results\": patching_results\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting: Heatmap of layer vs. token effects\n",
    "N_LAYERS = len(patching_results)\n",
    "seq_len = len(clean_tokens)\n",
    "layer_token_effects = np.zeros((N_LAYERS, seq_len))\n",
    "\n",
    "for layer in range(N_LAYERS):\n",
    "    for token_idx in range(seq_len):\n",
    "        layer_token_effects[layer, token_idx] = float(patching_results[layer][f\"token_{token_idx}\"].value)\n",
    "\n",
    "clean_diff = float(patching_results_total[\"clean_run_logit_difference\"].item())\n",
    "corrupted_diff = float(patching_results_total[\"corrupted_run_logit_difference\"].item())\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "im = plt.imshow(layer_token_effects, cmap='RdBu', aspect='auto', vmin=-0.5, vmax=0.5)\n",
    "plt.colorbar(im, label='Normalized Patching Effect')\n",
    "\n",
    "# Customize axes with token text (optional)\n",
    "token_labels = [llm.tokenizer.decode([tok]) for tok in clean_tokens]\n",
    "plt.xlabel('Token Position', fontsize=12)\n",
    "plt.ylabel('Layer', fontsize=12)\n",
    "plt.title('Patching Effects by Layer and Token\\n(Clean: \"Paris\" vs Corrupted: \"Berlin\")', fontsize=14)\n",
    "plt.xticks(np.arange(seq_len), labels=token_labels, fontsize=10, rotation=45, ha='right')\n",
    "plt.yticks(np.arange(N_LAYERS), labels=[f'{i}' for i in range(N_LAYERS)], fontsize=10)\n",
    "\n",
    "# Add clean/corrupted context\n",
    "plt.figtext(0.9, 0.02, f'Clean Logit Diff: {clean_diff:.3f}\\nCorrupted Logit Diff: {corrupted_diff:.3f}',\n",
    "            fontsize=11, ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('patching_effects_heatmap.pdf', format='pdf', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting: Single heatmap with Attention and MLP interleaved on Y-axis\n",
    "N_LAYERS = len(patching_results)\n",
    "seq_len = len(clean_tokens)\n",
    "\n",
    "# Extract data for attention and MLP, interleaving them on the Y-axis\n",
    "combined_effects = np.zeros((N_LAYERS * 2, seq_len))  # Each layer has two rows: Attention and MLP\n",
    "\n",
    "for layer in range(N_LAYERS):\n",
    "    for token_idx in range(seq_len):\n",
    "        attn_effect = float(patching_results[layer][\"attn\"][f\"token_{token_idx}\"].value)\n",
    "        mlp_effect = float(patching_results[layer][\"mlp\"][f\"token_{token_idx}\"].value)\n",
    "        combined_effects[layer * 2, token_idx] = attn_effect      # Attention row\n",
    "        combined_effects[layer * 2 + 1, token_idx] = mlp_effect  # MLP row\n",
    "\n",
    "clean_diff = float(patching_results_total[\"clean_run_logit_difference\"].item())\n",
    "corrupted_diff = float(patching_results_total[\"corrupted_run_logit_difference\"].item())\n",
    "\n",
    "# Create the heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "im = plt.imshow(combined_effects, cmap='RdBu', aspect='auto', vmin=-0.5, vmax=0.5)\n",
    "plt.colorbar(im, label='Normalized Patching Effect')\n",
    "\n",
    "# Customize axes\n",
    "token_labels = [llm.tokenizer.decode([tok]) for tok in clean_tokens]\n",
    "plt.xlabel('Token', fontsize=12)\n",
    "plt.ylabel('Layer (Attention | MLP)', fontsize=12)\n",
    "plt.title('Patching Effects by Layer and Token\\n(Clean: \"Paris\" vs Corrupted: \"Berlin\")', fontsize=14)\n",
    "\n",
    "# X-axis: Token labels\n",
    "plt.xticks(np.arange(seq_len), labels=token_labels, fontsize=10, rotation=45, ha='right')\n",
    "\n",
    "# Y-axis: Interleave Attention and MLP labels for each layer\n",
    "y_labels = []\n",
    "for layer in range(N_LAYERS):\n",
    "    y_labels.extend([f'Attn {layer}', f'MLP {layer}'])\n",
    "plt.yticks(np.arange(N_LAYERS * 2), labels=y_labels, fontsize=10)\n",
    "\n",
    "# Add clean/corrupted context\n",
    "plt.figtext(0.5, 0.01, f'Clean Logit Diff: {clean_diff:.3f} | Corrupted Logit Diff: {corrupted_diff:.3f}', \n",
    "            fontsize=11, ha='center')\n",
    "\n",
    "# Adjust layout and save\n",
    "plt.tight_layout(rect=[0, 0.05, 1, 0.95])\n",
    "plt.savefig('patching_effects_heatmap_single_swapped.pdf', format='pdf', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "helmholtz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
