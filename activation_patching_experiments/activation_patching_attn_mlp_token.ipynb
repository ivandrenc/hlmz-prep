{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation Patching by attention layers, mlps, and every token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnsight import LanguageModel\n",
    "import einops\n",
    "import torch\n",
    "torch.set_grad_enabled(False)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = LanguageModel(\"meta-llama/Llama-3.2-1B\", device_map=\"auto\", torch_dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.model.layers[0].mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_LAYERS = llm.model.config.num_hidden_layers\n",
    "N_HEADS = llm.model.config.num_attention_heads\n",
    "hidden_size = llm.model.layers[0].self_attn.q_proj.weight.shape[0]\n",
    "HEAD_SIZE = hidden_size // N_HEADS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"The capital of France is Paris.\n",
    "The capital of France is Berlin.\n",
    "Now I will give the correct answer.\n",
    "The capital of France is\"\"\"\n",
    "\n",
    "corrupted_prompt = \"\"\"The capital of France is Paris.\n",
    "The capital of France is Berlin.\n",
    "Now I will give the incorrect answer.\n",
    "The capital of France is\"\"\"\n",
    "\n",
    "prompts = [prompt, corrupted_prompt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the answers to these prompts, formatted as (correct, incorrect)\n",
    "answers = [\n",
    "    (\" Paris\", \" Berlin\"),\n",
    "    (\" Berlin\", \" Paris\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize clean and corrupted prompts\n",
    "clean_tokens = llm.tokenizer(prompts[0], return_tensors=\"pt\")[\"input_ids\"]\n",
    "corrupted_tokens = llm.tokenizer(prompts[1], return_tensors=\"pt\")[\"input_ids\"]\n",
    "\n",
    "answer_token_indices = [\n",
    "    [llm.tokenizer(answers[i][j])[\"input_ids\"][1] for j in range(2)]\n",
    "    for i in range(len(answers))\n",
    "]\n",
    "print(\"answer_token_indices=\", answer_token_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patching_results = []\n",
    "z_l = {}\n",
    "\n",
    "with llm.trace() as tracer:\n",
    "    # Clean run, grab clean activations for layer\n",
    "    with tracer.invoke(prompts[0]) as invoker:\n",
    "        clean_tokens = invoker.inputs[0][0][\"input_ids\"][0]\n",
    "        for layer in range(N_LAYERS):\n",
    "            z_l[layer] = {\n",
    "                \"attn\": llm.model.layers[layer].self_attn.output.save(),\n",
    "                \"mlp\": llm.model.layers[layer].mlp.output.save()\n",
    "            }\n",
    "        \n",
    "        # Get logits from lm_head\n",
    "        clean_logits = llm.lm_head.output\n",
    "        clean_logit_difference = (clean_logits[0, -1, answer_token_indices[0][0]] - clean_logits[0, -1, answer_token_indices[0][1]]).save()\n",
    "\n",
    "    # Corrupter run, grab the corrupted logits for later comparison    \n",
    "    with tracer.invoke(prompts[1]) as invoker:\n",
    "        corrupted_tokens = invoker.inputs[0][0][\"input_ids\"][0]\n",
    "        corrupted_logits = llm.lm_head.output\n",
    "        corrupted_logit_difference = (corrupted_logits[0, -1, answer_token_indices[0][0]] - corrupted_logits[0, -1, answer_token_indices[0][1]]).save()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patching\n",
    "with llm.trace() as tracer:\n",
    "    # Start with the activation patching: iterate through all the layers\n",
    "    for layer in range(N_LAYERS):\n",
    "        patch_results = []\n",
    "        for token_idx in range(len(clean_tokens)):  \n",
    "            with tracer.invoke(prompts[1]) as invoker:\n",
    "                llm.model.layers[layer].self_attn.output[0][:, token_idx, :] = z_l[layer][\"attn\"][0][:, token_idx, :]\n",
    "                llm.model.layers[layer].mlp.output[:, token_idx, :] = z_l[layer][\"mlp\"][:, token_idx, :]\n",
    "                patched_logits = llm.lm_head.output\n",
    "                patched_logit_difference = (patched_logits[0, -1, answer_token_indices[0][0]] - patched_logits[0, -1, answer_token_indices[0][1]]).save()\n",
    "                patched_result = (patched_logit_difference - corrupted_logit_difference) / (clean_logit_difference - corrupted_logit_difference)\n",
    "                patch_results.append(patched_result.item().save())\n",
    "                patching_results.append(patch_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patching_results = {\n",
    "    \"clean_run_logit_difference\": clean_logit_difference,\n",
    "    \"corrupted_run_logit_difference\": corrupted_logit_difference,\n",
    "    \"patching_results\": patching_results\n",
    "}\n",
    "patching_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract layer-wise patching results (flatten the nested list)\n",
    "layer_effects = [float(result[0].value) for result in patching_results[\"patching_results\"]]  # Ensure plain flo.item().item()\n",
    "layers = np.arange(len(layer_effects))  # Layer indices: 0 to 15\n",
    "\n",
    "# Convert tensors to Python scalars explicitly\n",
    "clean_diff = float(patching_results[\"clean_run_logit_difference\"].item())  # Extract scalar\n",
    "corrupted_diff = float(patching_results[\"corrupted_run_logit_difference\"].item())  # Extract scalar\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(layers, layer_effects, color=np.where(np.array(layer_effects) >= 0, 'skyblue', 'salmon'))\n",
    "plt.axhline(0, color='gray', linestyle='-', linewidth=0.5)  # Zero line for reference\n",
    "plt.axhline(1, color='green', linestyle='--', linewidth=1, label=f'Clean Run (Logit Diff = {clean_diff:.3f})')\n",
    "plt.axhline(0, color='red', linestyle='--', linewidth=1, label=f'Corrupted Run (Normalized = 0)')\n",
    "\n",
    "# Customize\n",
    "plt.xlabel('Attention Layer', fontsize=12)\n",
    "plt.ylabel('Normalized Patching Effect', fontsize=12)\n",
    "plt.title('Effect of Patching Attention Layers on Logit Difference\\n(Clean: \"Paris\" vs Corrupted: \"Berlin\")', fontsize=14)\n",
    "plt.xticks(layers, fontsize=10)\n",
    "plt.yticks(np.arange(-0.6, 1.2, 0.2), fontsize=10)\n",
    "plt.legend(fontsize=11)\n",
    "\n",
    "# Add grid for readability\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Annotate key bars (e.g., max positive, max negative)\n",
    "max_pos_idx = np.argmax(layer_effects)\n",
    "max_neg_idx = np.argmin(layer_effects)\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    if bar.get_x() in [max_pos_idx, max_neg_idx]:\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height, f'{height:.3f}', \n",
    "                 ha='center', va='bottom' if height >= 0 else 'top', fontsize=10, color='black')\n",
    "\n",
    "# Tight layout and save\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('patching_effects.pdf', format='pdf', dpi=300)  # Save as high-quality PDF for paper\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "helmholtz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
