{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnsight import LanguageModel\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = [\"Qwen/Qwen2.5-3B\", \"meta-llama/Llama-3.2-3B\"]\n",
    "\n",
    "llm = LanguageModel(MODELS[0], device_map=\"auto\", torch_dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "print(os.getcwd())\n",
    "df = pd.read_csv(os.path.join(os.getcwd(), \"sentences.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\"prompt_correct\": {\"correct_token_prob\": [], \"incorrect_token_prob\": []}, \"prompt_incorrect\": {\"correct_token_prob\": [], \"incorrect_token_prob\": []}}\n",
    "for i in range(len(df)):\n",
    "    # Define the answers to these prompts, formatted as (correct, incorrect)\n",
    "    answers = [\n",
    "        (df.iloc[i][\"answer_sentence1\"], df.iloc[i][\"answer_sentence2\"]),\n",
    "    ]\n",
    "\n",
    "    answer_token_indices = [\n",
    "        [llm.tokenizer.encode(answers[i][j])[0] for j in range(2)]\n",
    "        for i in range(len(answers))\n",
    "    ]\n",
    "    print(answer_token_indices)\n",
    "    print(answers)\n",
    "    \n",
    "    s1 = df.iloc[i][\"sentence1\"]\n",
    "    s2 = df.iloc[i][\"sentence2\"]\n",
    "    last_sentence = df.iloc[i][\"last_sentence\"]\n",
    "    prompt_correct = f\"{s1}\\n{s2}\\nThis was the correct sentence:\\n{last_sentence}\"\n",
    "    prompt_incorrect = f\"{s1}\\n{s2}\\nThis was the false sentence:\\n{last_sentence}\"\n",
    "    print(prompt_correct)\n",
    "    print(prompt_incorrect)\n",
    "    with llm.trace(prompt_correct): \n",
    "        output = llm.lm_head.output\n",
    "        logits = output[0, -1]  # Get logits for last position\n",
    "        probabilities = F.softmax(logits, dim=-1)  # Apply softmax to get probabilities\n",
    "        \n",
    "        # Get probabilities for specific tokens\n",
    "        correct_token_prob = probabilities[answer_token_indices[0][0]].item().save()\n",
    "        incorrect_token_prob = probabilities[answer_token_indices[0][1]].item().save()\n",
    "        \n",
    "        # Store results\n",
    "        results[\"prompt_correct\"][\"correct_token_prob\"].append(correct_token_prob)\n",
    "        results[\"prompt_correct\"][\"incorrect_token_prob\"].append(incorrect_token_prob)\n",
    "    print(\"correct token prob\")\n",
    "    print(correct_token_prob)\n",
    "    print(incorrect_token_prob)\n",
    "    \n",
    "    with llm.trace(prompt_incorrect):\n",
    "        output = llm.lm_head.output\n",
    "        logits = output[0, -1]  # Get logits for last position\n",
    "        probabilities = F.softmax(logits, dim=-1)  # Apply softmax to get probabilities\n",
    "        \n",
    "        # Get probabilities for specific tokens\n",
    "        correct_token_prob = probabilities[answer_token_indices[0][0]].item().save()\n",
    "        incorrect_token_prob = probabilities[answer_token_indices[0][1]].item().save()\n",
    "        \n",
    "        # Store results\n",
    "        results[\"prompt_incorrect\"][\"correct_token_prob\"].append(correct_token_prob)\n",
    "        results[\"prompt_incorrect\"][\"incorrect_token_prob\"].append(incorrect_token_prob)\n",
    "    print(\"incorrect token prob\")\n",
    "    print(correct_token_prob)\n",
    "    print(incorrect_token_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data with all individual probabilities\n",
    "data = []\n",
    "for prompt_type in [\"prompt_correct\", \"prompt_incorrect\"]:\n",
    "    for idx, (correct_prob, incorrect_prob) in enumerate(zip(\n",
    "        [val.value for val in results[prompt_type][\"correct_token_prob\"]], \n",
    "        [val.value for val in results[prompt_type][\"incorrect_token_prob\"]]\n",
    "    )):\n",
    "        data.append({\n",
    "            \"Prompt\": prompt_type,\n",
    "            \"Probability Type\": \"correct_token_prob\",\n",
    "            \"Probability\": correct_prob\n",
    "        })\n",
    "        data.append({\n",
    "            \"Prompt\": prompt_type,\n",
    "            \"Probability Type\": \"incorrect_token_prob\",\n",
    "            \"Probability\": incorrect_prob\n",
    "        })\n",
    "\n",
    "df_plot = pd.DataFrame(data)\n",
    "\n",
    "# Create the bar plot with error bars\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(\n",
    "    x=\"Prompt\",\n",
    "    y=\"Probability\",\n",
    "    hue=\"Probability Type\",\n",
    "    data=df_plot,\n",
    "    errorbar=\"ci\",  # 95% confidence interval (default)\n",
    "    capsize=0.1     # Add caps to error bars for better visibility\n",
    ")\n",
    "\n",
    "plt.title('Probabilities by Prompt Type with Error Bars')\n",
    "plt.xlabel('Prompt Type')\n",
    "plt.ylabel('Probability')\n",
    "plt.legend(title='Probability Type')\n",
    "plt.ylim(0, 1)  # Probabilities range from 0 to 1\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "helmholtz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
